from ultralytics import YOLO
import cv2
import xml.etree.ElementTree as ET
import numpy as np


def detect_boxes(image):
    # do the prediction with confidence level of maximum 0.2; iou allows for intersection of predicted boxes (lower values are stricter)
    model = YOLO('./models/best.pt')
    # force model to use cpu even if trained on gpu
    results = model(image, conf=0.05, iou=0.25, device='cpu', classes=1) # 1=cars only for transfer learning model 
    return results[0]

def export_to_xml(prediction, display_output=False, testing=False, write_xml=True):
    '''
    Creates an XML-structure with coordinates of the boxes.
    '''
    
    # Create the XML structure
    root = ET.Element("parking", id='/Users/margarita.samuseva/neuefische/pklot/data')
    contours = []
    labels = []
    id_counter = 1
    for box in prediction.boxes:
        # Create the <space> which equals to one parking spot
        label = int(box.cls.item())
        space = ET.SubElement(root, "space", id=str(id_counter), occupied=str(label), confidence=str(round(box.conf[0].item(), 4)))
        # Get the cords in xywh format
        cords = box.xywh[0].tolist()
        x, y, w, h = [round(x) for x in cords]
        # Get the cords in xyxy format
        cords = box.xyxy[0].tolist()
        x1, y1, x2, y2 = [round(x) for x in cords]
        # Rotated rectangle, that is not rotated - just keeping this for naming convention
        rotated_rect = ET.SubElement(space, "rotatedRect")
        ET.SubElement(rotated_rect, "center", x=str(x), y=str(y))
        ET.SubElement(rotated_rect, "size", w=str(w), h=str(h))
        # Contour
        contour = ET.SubElement(space, "contour")
        ET.SubElement(contour, "point", x=str(x1), y=str(y1))
        ET.SubElement(contour, "point", x=str(x2), y=str(y1))
        ET.SubElement(contour, "point", x=str(x2), y=str(y2))
        ET.SubElement(contour, "point", x=str(x1), y=str(y2))
        contours.append([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])
        labels.append(label)
        id_counter += 1
    
    # format XML and make it more readable    
    prettify_xml(root)
    
    # Convert the XML structure to a string
    xml_string = ET.tostring(root, encoding='unicode')
    
    #Save the xml string to a file
    # with open('/Users/margarita.samuseva/neuefische/pklot/modeling/output.xml', 'w') as f:
    #     f.write(xml_string)
    
    if display_output:
        print("XML content generated successfully.")
        return xml_string
    if testing:
        return contours, labels, xml_string
    else:
        return xml_string
    

## Helper functions.

# make the xml code more readable
def prettify_xml(element, indent='  '):
    queue = [(0, element)]  # (level, element)
    while queue:
        level, element = queue.pop(0)
        children = list(element)
        if children:
            element.text = '\n' + indent * (level+1)  # for child open
        if queue:
            element.tail = '\n' + indent * queue[0][0]  # for sibling open
        else:
            element.tail = '\n' + indent * (level-1)  # for parent close
        queue[0:0] = [(level + 1, child) for child in children]

# Helper functions
def remove_boxes_from_xml(xml_string, ids_to_remove):
    ''' 
    Removes boxes from XML file.
    Creates an XML file with reduced numer of recognized boxes.
    '''
    # Parse the XML string
    tree = ET.ElementTree(ET.fromstring(xml_string))
    root = tree.getroot()

    # Iterate over 'space' elements and remove those with matching IDs
    for space in root.findall('.//space'):
        if int(space.get('id')) in ids_to_remove:
            root.remove(space)

    # Return the modified XML as a string
    return ET.tostring(root, encoding='unicode')

def show_images_with_boxes(image, xml_string):
    '''
    Reads in an XML with predefined structure.
    The XML contains the coordinates of the boxes.
    OUTPUT:
    Image with not classified boxes on top.
    '''

    # Read XML-file
    #tree = ET.parse(xml_path)
    #root = tree.getroot()
    
    # Read XML-structured string.
    # XML-String analysieren
    root = ET.fromstring(xml_string)

    # Kopiere das Originalbild f√ºr die Anzeige der Boxen
    image_with_boxes = image.copy()

    # Iteriere durch jede Box im XML
    for space in root.iter('space'):
        space_id = int(space.attrib['id'])

        # Extrahiere Koordinaten und Winkel aus XML (Konturkoordinaten)
        contour_points = []
        for point in space.iter('point'):
            x = int(point.attrib['x'])
            y = int(point.attrib['y'])
            contour_points.append((x, y))

        # Konvertiere die Konturpunkte in ein NumPy-Array
        contour_np = np.array(contour_points, dtype=np.int32)
        contour_np = contour_np.reshape((-1, 1, 2))

        # Zeichne ein Rechteck um die Konturpunkte auf dem Bild mit Boxen
        cv2.polylines(image_with_boxes, [contour_np], isClosed=True, color=(255, 0, 0), thickness=2)

        # Extrahiere Zentrum aus XML
        center_x = float(space.find('./rotatedRect/center').attrib['x'])
        center_y = float(space.find('./rotatedRect/center').attrib['y'])
        center = (int(center_x), int(center_y))

        # Beschrifte das Bild mit der Box-ID und schwarzem Hintergrund
        text = str(space_id)
        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
        text_padding = 3
        background_size = (text_size[0] + 2 * text_padding, text_size[1] + 2 * text_padding)
        text_x = center[0] - background_size[0] // 2
        text_y = center[1] - 5
        cv2.rectangle(image_with_boxes, (text_x, text_y - text_size[1] - text_padding),
                      (text_x + background_size[0], text_y + text_size[1] + text_padding), (0, 0, 0), -1)
        cv2.putText(image_with_boxes, text, (text_x + text_padding, text_y + text_size[1] - text_padding),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2, cv2.LINE_AA)

    # Anzeigen des Bildes mit den eingezeichneten Boxen im Output
    # plt.imshow(cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB))
    # plt.axis('off')
    # plt.show()
    return image_with_boxes


def run_detection(image):
        
    prediction = detect_boxes(image)
    xml_str = export_to_xml(prediction)
    
    return prediction, xml_str

if __name__ == "__main__":
    image_path ='/Users/margarita.samuseva/neuefische/pklot/data/PKLot/PKLot/PUCPR/Cloudy/2012-09-12/2012-09-12_06_05_16.jpg'
    image = cv2.imread(image_path)
    image_new, result = run_detection(image)

    